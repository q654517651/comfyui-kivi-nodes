"""
è§†é¢‘å¸§æå–èŠ‚ç‚¹
æå–è§†é¢‘åºåˆ—çš„å‰ N å¸§å’Œå N å¸§ï¼Œå¹¶ç”Ÿæˆ VAE è’™ç‰ˆ
"""

import torch
from typing import Tuple


class FrameExtractor:
    """
    æå–è§†é¢‘åºåˆ—çš„é¦–å°¾å¸§ï¼Œç”Ÿæˆç”¨äº VAE çš„è’™ç‰ˆå’Œé®ç½©è§†é¢‘
    """
    
    DESCRIPTION = "æå–è§†é¢‘é¦–å°¾å¸§å¹¶é¢ å€’é¡ºåºï¼Œç”Ÿæˆ VAE è’™ç‰ˆå’Œé®ç½©è§†é¢‘ï¼Œç”¨äºè§†é¢‘å¾ªç¯ä¼˜åŒ–ã€‚"
    
    # @classmethod
    # def INPUT_TYPES(cls):
    #     return {
    #         "required": {
    #             "frames": (
    #                 "IMAGE",
    #                 {
    #                     "tooltip": "è¾“å…¥å›¾åƒåºåˆ— (batch, height, width, channels)ï¼Œå€¼èŒƒå›´ [0, 1]"
    #                 }
    #             ),
    #             "crossfade_frames": (
    #                 "INT",
    #                 {
    #                     "default": 10,
    #                     "min": 0,
    #                     "max": 1000,
    #                     "step": 1,
    #                     "tooltip": "é¦–å°¾å„æå–ç”¨äºäº¤å‰æº¶è§£çš„å¸§æ•°"
    #                 }
    #             ),
    #             "mask_frames": (
    #                 "INT",
    #                 {
    #                     "default": 0,
    #                     "min": 0,
    #                     "max": 1000,
    #                     "step": 1,
    #                     "tooltip": "ä¸­é—´è’™ç‰ˆåŒºçš„å¸§æ•°"
    #                 }
    #             ),
    #             "discard_frames": (
    #                 "INT",
    #                 {
    #                     "default": 0,
    #                     "min": 0,
    #                     "max": 1000,
    #                     "step": 1,
    #                     "tooltip": "é¦–å°¾å„ä¸¢å¼ƒçš„å¸§æ•°ï¼ˆå¡«å……ç°è‰²è®©VAEé‡å»ºï¼‰"
    #                 }
    #             ),
    #             "fill_color": (
    #                 "STRING",
    #                 {
    #                     "default": "#7F7F7F",
    #                     "tooltip": "å¡«å……é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼Œå¦‚ #7F7F7Fï¼‰"
    #                 }
    #             ),
    #             "ensure_4n_plus_1": (
    #                 "BOOLEAN",
    #                 {
    #                     "default": True,
    #                     "tooltip": "è‡ªåŠ¨è°ƒæ•´å¸§æ•°æ»¡è¶³ 4n+1 (VAEç¼–ç è¦æ±‚)ï¼Œä¸è¶³çš„å¸§æ•°ä¼šå¢åŠ åˆ°ä¸­é—´è’™ç‰ˆåŒº"
    #                 }
    #             ),
    #         }
    #     }
    #
    # RETURN_TYPES = ("IMAGE", "IMAGE", "IMAGE", "MASK", "IMAGE")
    # RETURN_NAMES = (
    #     "head_frames",
    #     "tail_frames",
    #     "middle_frames",
    #     "mask",
    #     "masked_video"
    # )
    # FUNCTION = "extract_frames"
    # CATEGORY = "kivi_nodes"
    
    def extract_frames(
        self,
        frames: torch.Tensor,
        crossfade_frames: int,
        mask_frames: int,
        discard_frames: int,
        fill_color: str,
        ensure_4n_plus_1: bool = True
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        æå–é¦–å°¾å¸§å¹¶é¢ å€’é¡ºåºï¼Œç”Ÿæˆ VAE è’™ç‰ˆ
        
        è¾“å‡ºé¡ºåºï¼šd + e + mask + a + b
        
        Args:
            frames: è¾“å…¥å¸§åºåˆ—ï¼Œå½¢çŠ¶ (N, H, W, C)
            crossfade_frames: é¦–å°¾å„æå–ç”¨äºäº¤å‰æº¶è§£çš„å¸§æ•°
            mask_frames: ä¸­é—´è’™ç‰ˆåŒºçš„å¸§æ•°
            discard_frames: é¦–å°¾å„ä¸¢å¼ƒçš„å¸§æ•°
            fill_color: å¡«å……é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼‰
            ensure_4n_plus_1: æ˜¯å¦å¼ºåˆ¶è¾“å‡ºå¸§æ•°ä¸º 4n+1
            
        Returns:
            (head_frames, tail_frames, middle_frames, mask, masked_video)
        """
        N = frames.shape[0]
        H, W, C = frames.shape[1], frames.shape[2], frames.shape[3]
        device = frames.device
        dtype = frames.dtype
        
        # è§£æé¢œè‰²
        fill_color = fill_color.strip()
        if fill_color.startswith('#'):
            fill_color = fill_color[1:]
        try:
            r = int(fill_color[0:2], 16) / 255.0
            g = int(fill_color[2:4], 16) / 255.0
            b = int(fill_color[4:6], 16) / 255.0
            gray_color = torch.tensor([r, g, b], dtype=dtype, device=device)
        except:
            # é»˜è®¤ä¸­ç°è‰²
            gray_color = torch.tensor([0.5, 0.5, 0.5], dtype=dtype, device=device)
        
        # åˆ›å»ºå ä½ç¬¦ï¼ˆ1x1 é»‘è‰²å›¾ç‰‡ï¼‰
        placeholder = torch.zeros((1, 1, 1, C), dtype=dtype, device=device)
        
        # åŸè§†é¢‘åˆ†æ®µé€»è¾‘ï¼š
        # crossfade_frames æ˜¯é¦–å°¾å„æå–çš„å¸§æ•°
        # discard_frames æ˜¯ä» crossfade æ®µçš„ä¸¤ç«¯"åƒæ‰"çš„å¸§æ•°
        #
        # å¤´éƒ¨ crossfade æ®µ [0, crossfade_frames):
        #   a: [0, discard_frames) - å¤´éƒ¨ä¸¢å¼ƒï¼ˆå¡«å……çº¯è‰²ï¼‰
        #   b: [discard_frames, crossfade_frames) - å¤´éƒ¨å®é™…ä½¿ç”¨ï¼ˆåŸè§†é¢‘ï¼‰
        #
        # å°¾éƒ¨ crossfade æ®µ [N-crossfade_frames, N):
        #   d: [N-crossfade_frames, N-discard_frames) - å°¾éƒ¨å®é™…ä½¿ç”¨ï¼ˆåŸè§†é¢‘ï¼‰
        #   e: [N-discard_frames, N) - å°¾éƒ¨ä¸¢å¼ƒï¼ˆå¡«å……çº¯è‰²ï¼‰
        #
        # c: ä¸­é—´éƒ¨åˆ†ï¼ˆä¸ä½¿ç”¨ï¼‰
        
        # æå– b (head_frames) - å¤´éƒ¨å®é™…ä½¿ç”¨çš„åŸè§†é¢‘
        b_start = discard_frames
        b_end = crossfade_frames
        if b_end <= N and b_start < b_end and discard_frames < crossfade_frames:
            b = frames[b_start:b_end]
            b_count = b_end - b_start
        else:
            b = placeholder
            b_count = 0
        
        # æå– d (tail_frames) - å°¾éƒ¨å®é™…ä½¿ç”¨çš„åŸè§†é¢‘
        d_start = N - crossfade_frames
        d_end = N - discard_frames
        if d_start >= 0 and d_start < d_end and d_end <= N and discard_frames < crossfade_frames:
            d = frames[d_start:d_end]
            d_count = d_end - d_start
        else:
            d = placeholder
            d_count = 0
        
        # æå– c (middle_frames)
        c_start = crossfade_frames
        c_end = N - crossfade_frames
        if c_end > c_start:
            c = frames[c_start:c_end]
        else:
            c = placeholder
        
        # a å’Œ e çš„å¸§æ•°ï¼ˆçº¯è‰²å¡«å……ï¼Œä¸ä»åŸè§†é¢‘æå–ï¼‰
        a_count = discard_frames
        e_count = discard_frames
        
        # è®¡ç®—åŸºç¡€è¾“å‡ºé•¿åº¦
        output_length = d_count + e_count + mask_frames + a_count + b_count
        
        # è‡ªåŠ¨è°ƒæ•´å¸§æ•°ä¸º 4n+1
        if ensure_4n_plus_1 and output_length > 0:
            # ç›®æ ‡å¸§æ•°ï¼š((output_length - 1) // 4 + 1) * 4 + 1 (å¦‚æœä¸æ»¡è¶³)
            # ç®€å•ç®—æ³•ï¼š
            # target = ceil((x-1)/4)*4 + 1
            # ä½†æ˜¯ python çš„ // æ˜¯å‘ä¸‹å–æ•´ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ç”¨ math.ceil æˆ–è€…æ‰‹åŠ¨é€»è¾‘
            # (output_length - 1) % 4
            
            remainder = (output_length - 1) % 4
            if remainder != 0:
                needed = 4 - remainder
                mask_frames += needed
                output_length += needed
                # print(f"è‡ªåŠ¨è°ƒæ•´å¸§æ•°: å¢åŠ  {needed} å¸§ maskï¼Œæ€»å¸§æ•° {output_length - needed} -> {output_length} (æ»¡è¶³ 4n+1)")
        
        # ç”Ÿæˆ mask å’Œ masked_video
        # è¾“å‡ºé¡ºåº: d + e + mask + a + b
        # è’™ç‰ˆ: [é»‘d | ç™½e | ç™½mask | ç™½a | é»‘b]
        # é®ç½©: [dåŸè§†é¢‘ | ç°e | ç°mask | ç°a | båŸè§†é¢‘]
        
        if output_length == 0:
            # æ²¡æœ‰è¾“å‡ºï¼Œè¿”å›å ä½ç¬¦
            mask = torch.zeros((1, H, W), dtype=dtype, device=device)
            masked_video = torch.zeros((1, H, W, C), dtype=dtype, device=device)
            return (placeholder, placeholder, placeholder, mask, masked_video)
        
        # åˆå§‹åŒ– mask å’Œ masked_video
        mask = torch.zeros((output_length, H, W), dtype=dtype, device=device)
        masked_video = torch.zeros((output_length, H, W, C), dtype=dtype, device=device)
        
        idx = 0
        
        # 1. d (å°¾éƒ¨å®é™…ä½¿ç”¨) - é»‘è‰²è’™ç‰ˆï¼ŒåŸè§†é¢‘
        if d_count > 0:
            mask[idx:idx+d_count] = 0.0  # é»‘è‰²ï¼ˆä¿ç•™ï¼‰
            masked_video[idx:idx+d_count] = d
            idx += d_count
        
        # 2. e (å°¾éƒ¨ä¸¢å¼ƒæ®µ) - ç™½è‰²è’™ç‰ˆï¼Œç°è‰²è§†é¢‘
        if e_count > 0:
            mask[idx:idx+e_count] = 1.0  # ç™½è‰²ï¼ˆé‡å»ºï¼‰
            masked_video[idx:idx+e_count] = gray_color.view(1, 1, 1, 3)
            idx += e_count
        
        # 3. maskåŒº - ç™½è‰²è’™ç‰ˆï¼Œç°è‰²è§†é¢‘
        if mask_frames > 0:
            mask[idx:idx+mask_frames] = 1.0  # ç™½è‰²ï¼ˆé‡å»ºï¼‰
            masked_video[idx:idx+mask_frames] = gray_color.view(1, 1, 1, 3)
            idx += mask_frames
        
        # 4. a (å¤´éƒ¨ä¸¢å¼ƒæ®µ) - ç™½è‰²è’™ç‰ˆï¼Œç°è‰²è§†é¢‘
        if a_count > 0:
            mask[idx:idx+a_count] = 1.0  # ç™½è‰²ï¼ˆé‡å»ºï¼‰
            masked_video[idx:idx+a_count] = gray_color.view(1, 1, 1, 3)
            idx += a_count
        
        # 5. b (å¤´éƒ¨å®é™…ä½¿ç”¨) - é»‘è‰²è’™ç‰ˆï¼ŒåŸè§†é¢‘
        if b_count > 0:
            mask[idx:idx+b_count] = 0.0  # é»‘è‰²ï¼ˆä¿ç•™ï¼‰
            masked_video[idx:idx+b_count] = b
            idx += b_count
        
        return (b, d, c, mask, masked_video)


# # èŠ‚ç‚¹æ³¨å†Œ
# NODE_CLASS_MAPPINGS = {
#     "VideoFrameExtractor": VideoFrameExtractor,
# }
#
# NODE_DISPLAY_NAME_MAPPINGS = {
#     "VideoFrameExtractor": "ğŸ“¹ è§†é¢‘å¸§æå–å™¨",
# }

